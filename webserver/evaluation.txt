The performance of the web server is determined by factors including “nr_threads”. “nr_threads” is a parameter of the server, specifying the number of working threads available. In a nut shell, greater values of “nr_threads” results in a better preference. 

For a given number of “max_requests”, the performance of the server is expected to improve as the number of “nr_threads” increases. The test result and the graph named “plot-thread” revealed result different from expectation. The maximum number of request connections was set to 8 in the test conducted. The runtimes dramatically decreased as “nr_threads” increased from 0 to 8. A critical point was reached when “nr_threads” equaled to 8. After this point, the runtimes were plotted to be a near flat line. A reasonable explanation is that the server reached its context switch overhead at this critical point. No further improvement could be made for the server runing more than 8 threads.

For a fixed number of “nr_threads”, the server performance is expected to be consistant as the as the size of request queue increases. The performace of this program is determined by number of threads instead of the size of wait queue. Regardless the size of wait queue, the sever is designed to use all available threads to process any available request. 

The test result and the graph named “plot-request” support the expectation. The number of working threads was set to 8 during the test. As “max_requests” increasing from 0 to 8, the performance was nearly consistant. Small variance in runtime could be seen. A possible expalination is that the computer is not dedicated to only the test program. It has to schedule various threads and processes at the same time. The tester program may have to yield for some task with higher priority, causing various in runtime.  

The performace results of thread and request experiments are not expected to change since both tests were run under the condition that no cache is available for server.

For a constant number of “nr_threads” and “max_requests”, the overall performance is expected to improve as the size of cache increase. A larger cache size allows more files to be stored in cache instead of disk. Accessing data from cache is significantly faster than accessing data from disk. As a result, increasing the size of cache improves the performance of the program.

The test result and the graph called "plot-cachesize" collaborate with the overall expectation. The plot shows that the overall performance is increasing as the cache size grows. There may be trils that are not consistent with this conclusion due to following reason. Malloc is one of the slowest instructions in this program. A incresing size of cache also requires bigger amount of malloc instructions. A huge amount of malloc instructions slows down the run time. It may overshadow the benefit of larger cache size. In addition, a trile may be slowed down by cache_evict algorithm. cache_evict function could be slow when the fruncion check all files in cache to search for available file to evict. 
